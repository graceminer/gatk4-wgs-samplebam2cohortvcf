configfile: "config.yaml"

import glob
import os

REF_FASTA = config["REF_FASTA"]

#[minerg01@li03c03 ~]$ ml bwa/0.7.8
#[minerg01@li03c03 ~]$ BWA_VERSION=$(bwa 2>&1 |     grep -e '^Version' |     sed 's/Version: //')
#[minerg01@li03c03 ~]$ echo $BWA_VERSION
#0.7.8-r455
BWA_VERSION = "0.7.8-r455"
COMPRESSION_LEVEL=2   

# cross check fingerprints (on the aligned.duplicates_marked.sorted.bam)
LOD_THRESHOLD=-20.0
CROSSCHECK_BY="READGROUP"
HAPLOTYPE_DATABASE_FILE="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/references-hg38-v0-Homo_sapiens_assembly38.haplotype_database.txt"

# check contamination
CONTAMINATION_SITES_UD="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/references-hg38-v0-Homo_sapiens_assembly38.contam.UD"
CONTAMINATION_SITES_BED="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/references-hg38-v0-Homo_sapiens_assembly38.contam.bed"
CONTAMINATION_SITES_MU="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/references-hg38-v0-Homo_sapiens_assembly38.contam.mu"
CONTAMINATION_UNDERESTIMATION_FACTOR=0.75
CONTAMINATION_SITES_PREFIX="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/references-hg38-v0-Homo_sapiens_assembly38.contam"
VerifyBamID = config["VerifyBamID"]

# base_recalibration_report
REF_DICT=config["REF_DICT"]
DBSNP_VCF=config["DBSNP_VCF"]

#INTERVALS = glob.glob("input/sequence_grouping/sequence_grouping_*.list")
INTERVALS =  glob.glob("input/intervals/sequence_grouping_unmapped_newline/sequence_grouping.unmapped_*.list")
#known_indels_sites_vcfs
KNOWN_SITES_MILLS1000G="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/resources-broad-hg38-v0-Mills_and_1000G_gold_standard.indels.hg38.vcf.gz"
KNOWN_SITES_HOMOSAPIENS="/sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/resources-broad-hg38-v0-Homo_sapiens_assembly38.known_indels.vcf.gz"



SNPEFF = config["SNPEFF"]
SNPSIFT = config["SNPSIFT"]
#GNOMAD = config["GNOMAD"]
MAGMA = config["MAGMA"]
#SNPSIFT_FILTER_IMPACT = config["SNPSIFT_FILTER_IMPACT"]
SNPSIFT_FILTER_IMPACT_TWO="(((ANN[0].IMPACT = 'HIGH') | (ANN[0].IMPACT = 'MODERATE')) & !(ANN[0].EFFECT = 'sequence_feature'))"
SNPSIFT_FILTER_BIOTYPE_PROTEIN_CODING = "(ANN[0].BIOTYPE = 'protein_coding')"
DATE=20201204
PHENO_COVARS_ALL = "../output/modules/pca_final/pheno_covars_all"
GENOME = config["GENOME"]
NAME = "1096013095.final.bam"
UBAM = ["A","B","C"] #,"D", "E" ,"F","G","H","I","J","K","L","M","N","O","P","Q","R","S","T","U"]
CHROMOSOMES = range(1, 23) # ["all"]
#PATH1 = os.getcwd()

#SAMPLES, = glob_wildcards("/sc/arion/projects/MMAAAS/ngs_res/gatk20200105/input/{samples}.final.bam")
#SAMPLES, = glob_wildcards("input/{samples}.final.bam")

#RGS, = glob_wildcards("../output/{wildcards.samples}/{rgs}.bam")
#RGS, = glob_wildcards("../output/{wildcards.samples}/{wildcards.samples}_{rgs}.bam")

(SAMPLE,RG) = glob_wildcards("../output/split_rg/{sample}/{rg}.bam")

#(SAMPLE,RG) = glob_wildcards("../output/{sample}/{rg}.bam")


scattergather:
    split=25
    
wildcard_constraints:
    chr="\d+"
    
localrules: main
#ruleorder: revertsam > sortsam    

rule main:
    input:
        expand("../output/unmapped_bam/{sample}/{rg}.unmapped.bam",zip, sample=SAMPLE,rg=RG), #default combinatorial function is product, which can be replaced with other functions in this case "zip()" to create a tuple so that expand doesnt create all combos of sample and rg which ends up swapping sample dirs and rg and producing all possible cobinations as opposed to sampleA/sampleA_rg_bam
	expand("../output/unmapped_bam/{sample}/{rg}.quality_yield_metrics",zip, sample=SAMPLE,rg=RG),
	expand("../output/aligned_bam/{sample}/{rg}.aligned.unsorted.bam",zip, sample=SAMPLE,rg=RG),
	expand("../output/aligned_bam/{sample}/{rg}.aligned.unsorted.bwa.stderr.log",zip, sample=SAMPLE,rg=RG),
	#expand("../output/duplicates_marked/{sample}/{rg}.aligned.unsorted.duplicates_marked.{ext}", zip, sample=SAMPLE, rg=RG, ext=["bam", "duplicate_metrics.txt"]),
	expand("../output/duplicates_marked/{sample}/{rg}.aligned.unsorted.duplicates_marked.bam", zip, sample=SAMPLE, rg=RG),
	expand("../output/sorted_bam/{sample}/{rg}.aligned.duplicates_marked.sorted.bam", zip, sample=SAMPLE, rg=RG),
	expand("../output/sorted_bam/{sample}/{rg}.aligned.duplicates_marked.sorted.crosscheck", zip, sample=SAMPLE, rg=RG), 	
	expand("../output/sorted_bam/{sample}/{rg}.aligned.duplicates_marked.sorted.preBqsr.selfSM", zip, sample=SAMPLE, rg=RG),
  	expand("../output/recalibrated_bam/{sample}/{rg}.aligned.duplicates_marked.recalibrated.bam", zip, sample=SAMPLE, rg=RG),
        expand("../output/recalibrated_bam/{sample}/{rg}.recal_data.csv", zip, sample=SAMPLE, rg=RG),
        


        
rule sortsam:
    input: lambda wildcards: [os.path.join('../output/','split_rg/',SAMPLE[i], x + '.bam') for i,x in enumerate(RG) if x == wildcards.rg]
    output: "../output/unmapped_bam/{sample}/{rg}.unmapped.bam"
    shell:
        """
        module load java/1.8.0_211  python/3.7.3  gatk/4.2.0.0
        
	gatk --java-options "-Xmx3g" \
        SortSam \
            --INPUT {input} \
            --OUTPUT {output} \
            --SORT_ORDER queryname \
            --MAX_RECORDS_IN_RAM 1000000

        module unload java/1.8.0_211  python/3.7.3 gatk/4.2.0.0
        """

rule collect_quality_yield_metrics:
    input: rules.sortsam.output
    output: "../output/unmapped_bam/{sample}/{rg}.quality_yield_metrics"
    #output: "../output/{sample}/{rg}.unmapped.bam.quality_yield_metrics"
    shell:
        """
        module load java/1.8.0_211  python/3.7.3 picard/2.22.3
		
     	java -Xms2000m -jar $PICARD \
             CollectQualityYieldMetrics \
             INPUT={input} \
             OQ=true  \
             OUTPUT={output}
	 module unload java/1.8.0_211  python/3.7.3 picard/2.22.3
        """
#REDO THE align_bam_bwa rule so that the log files are part of the output (they arent erased on job fail)
#separatte the lines of the sam2fq and merge alignment steps to clean up
rule align_bam_bwa:
    input: rules.sortsam.output
    output: bam="../output/aligned_bam/{sample}/{rg}.aligned.unsorted.bam",bwalog="../output/aligned_bam/{sample}/{rg}.aligned.unsorted.bwa.stderr.log"
    shell:
        """
	module load R/3.5.3 java/1.8.0_211 bwa/0.7.8  python/3.7.3 picard/2.22.3
	echo "modules loaded"	
	#mkdir -p ./../output/{wildcards.sample}/aligned_bam
 
	#BWA_VERSION=$(bwa 2>&1 | grep -e '^Version' | sed 's/Version: //')
	#echo $BWA_VERSION
	
	#set -o pipefail
    	#set -e

    	#if [-z $BWA_VERSION]; then
        #    exit 1;
    	#fi
	
	java -Xms1000m -Xmx1000m -jar $PICARD SamToFastq INPUT={input} FASTQ=/dev/stdout INTERLEAVE=true NON_PF=true | bwa mem -p -v 3 -t 16 /{REF_FASTA} /dev/stdin - 2> >(tee {output.bwalog} >&2) | java -Dsamjdk.compression_level=2 -Xms1000m -Xmx1000m -jar $PICARD MergeBamAlignment VALIDATION_STRINGENCY=SILENT EXPECTED_ORIENTATIONS=FR ATTRIBUTES_TO_RETAIN=X0 ATTRIBUTES_TO_REMOVE=NM ATTRIBUTES_TO_REMOVE=MD ALIGNED_BAM=/dev/stdin UNMAPPED_BAM={input} OUTPUT={output.bam} REFERENCE_SEQUENCE={REF_FASTA} PAIRED_RUN=true SORT_ORDER="unsorted" IS_BISULFITE_SEQUENCE=false ALIGNED_READS_ONLY=false CLIP_ADAPTERS=false MAX_RECORDS_IN_RAM=2000000 ADD_MATE_CIGAR=true MAX_INSERTIONS_OR_DELETIONS=-1 PRIMARY_ALIGNMENT_STRATEGY=MostDistant PROGRAM_RECORD_ID="bwamem" PROGRAM_GROUP_VERSION={BWA_VERSION} PROGRAM_GROUP_COMMAND_LINE="bwa mem -p -v 3 -t 16 {REF_FASTA}" PROGRAM_GROUP_NAME="bwamem" UNMAPPED_READ_STRATEGY=COPY_TO_TAG ALIGNER_PROPER_PAIR_FLAGS=true UNMAP_CONTAMINANT_READS=true ADD_PG_TAG_TO_READS=false

        java -Xms5000m -jar $PICARD \
          CollectMultipleMetrics \
          INPUT={output.bam} \
          OUTPUT="../output/aligned_bam/{wildcards.sample}/{wildcards.rg}.aligned.unsorted" \
          ASSUME_SORTED=true \
          PROGRAM=null \
          PROGRAM=CollectBaseDistributionByCycle \
          PROGRAM=CollectInsertSizeMetrics \
          PROGRAM=MeanQualityByCycle \
          PROGRAM=QualityScoreDistribution \
          METRIC_ACCUMULATION_LEVEL=null \
          METRIC_ACCUMULATION_LEVEL=ALL_READS
	"""
rule mark_duplicates:
    input: rules.align_bam_bwa.output.bam
    output: bam="../output/duplicates_marked/{sample}/{rg}.aligned.unsorted.duplicates_marked.bam",metrics="../output/duplicates_marked/{sample}/{rg}.aligned.unsorted.duplicates_marked.duplicate_metrics"
    shell:
        """
        module load java/1.8.0_211 python/3.7.3 picard/2.22.3

        #mkdir -p ../output/duplicates_marked/{wildcards.sample}/

        java -Dsamjdk.compression_level={COMPRESSION_LEVEL} -Xms10g -jar $PICARD \
          MarkDuplicates \
          INPUT={input} \
          OUTPUT={output.bam} \
          METRICS_FILE={output.metrics} \
          VALIDATION_STRINGENCY=SILENT \
          OPTICAL_DUPLICATE_PIXEL_DISTANCE=2500 \
          ASSUME_SORT_ORDER="queryname" \
          CLEAR_DT="false" \
          ADD_PG_TAG_TO_READS=false
        """


rule sort_bam:
    input: rules.mark_duplicates.output.bam
    output: "../output/sorted_bam/{sample}/{rg}.aligned.duplicates_marked.sorted.bam"
    shell:
        """
	module load R/3.5.3 java/1.8.0_211 python/3.7.3 picard/2.22.3

        java -Dsamjdk.compression_level={COMPRESSION_LEVEL} -Xms4000m -jar $PICARD \
          SortSam \
          INPUT={input} \
          OUTPUT={output} \
          SORT_ORDER="coordinate" \
          CREATE_INDEX=true \
          CREATE_MD5_FILE=true \
          MAX_RECORDS_IN_RAM=300000
        """

rule crosscheck_fingerprints:
    input: rules.sort_bam.output
    output: "../output/sorted_bam/{sample}/{rg}.aligned.duplicates_marked.sorted.crosscheck" 
    shell:
        """
	module load R/3.5.3 java/1.8.0_211 python/3.7.3 picard/2.22.3

        java -Dsamjdk.buffer_size=131072 -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xms2000m -jar $PICARD \
          CrosscheckFingerprints \
          OUTPUT={output} \
          HAPLOTYPE_MAP={HAPLOTYPE_DATABASE_FILE} \
          EXPECT_ALL_GROUPS_TO_MATCH=true \
          INPUT={input} \
          LOD_THRESHOLD={LOD_THRESHOLD} \
          CROSSCHECK_BY={CROSSCHECK_BY}
	"""
# DissableSanityCheck" false="" disable_sanity_check} \	

rule check_contamination:
    input: rules.sort_bam.output
    output: "../output/sorted_bam/{sample}/{rg}.aligned.duplicates_marked.sorted.preBqsr.selfSM"
    shell:
        """
	module load R/3.5.3 java/1.8.0_211 python/3.7.3 picard/2.22.3 verifyBamID/2014-02-13
        
        # UDPath, MeanPath, and BedPath are functional but depreciated abnd have been replaced with --SVDPrefix where you provide the prefix for all three files
        # First row are the keys (e.g., SEQ_SM, RG, FREEMIX), second row are the associated values
        # verifyBamID \
        # --Verbose \
        # --NumPC 4 \
        # --Output "../output/sorted_bam/{wildcards.sample}/{wildcards.rg}.aligned.duplicates_marked.sorted.preBqsr" \
        # --BamFile {input} \
        # --Reference {REF_FASTA} \
        # --UDPath {CONTAMINATION_SITES_UD} \
        # --MeanPath {CONTAMINATION_SITES_MU} \
        # --BedPath {CONTAMINATION_SITES_BED} \
        #  1>/dev/null
        # used to read from the selfSM file and calculate contamination, which gets printed out
        
	set -e
        # creates a "output_prefix".selfSM file, a TSV file with 2 rows, 19 columns.
        # need to download and compile the new version of VerifyBamID verifyBamID2 from https://github.com/Griffan/VerifyBamID
        # First row are the keys (e.g., SEQ_SM, RG, FREEMIX), second row are the associated values
        {VerifyBamID} \
        --Verbose \
        --NumPC 4 \
        --Output ../output/sorted_bam/{wildcards.sample}/{wildcards.rg}.aligned.duplicates_marked.sorted.preBqsr \
        --BamFile {input} \
        --Reference {REF_FASTA} \
        --SVDPrefix {CONTAMINATION_SITES_PREFIX} \
        --DisableSanityCheck \
        
        1>/dev/null
        
#        python3 - <<CODE
#        import csv
#        import sys
#        with open('{output}') as selfSM:
#            reader = csv.DictReader(selfSM, delimiter='\t')
#            i = 0
#            for row in reader:
#                if float(row["FREELK0"])==0 and float(row["FREELK1"])==0:
#                    # a zero value for the likelihoods implies no data. This usually indicates a problem rather than a real event.
#                    # if the bam isn't really empty, this is probably due to the use of a incompatible reference build between
#                    # vcf and bam.
#                   sys.stderr.write("Found zero likelihoods. Bam is either very-very shallow, or aligned to the wrong reference (relative to the vcf).")
#                   sys.exit(1)
#                print(float(row["FREEMIX"])/0.75)
#                i = i + 1
#                # there should be exactly one row, and if this isn't the case the format of the output is unexpectedly different
#                # and the results are not reliable.
#                if i != 1:
#                    sys.stderr.write("Found %d rows in .selfSM file. Was expecting exactly 1. This is an error"%(i))
#                    sys.exit(2)
#        CODE
1>/dev/null
        
python3 <<CODE
import csv
import sys
with open('../output/sorted_bam/1102781231/1102781231_TAATGCGC_H55GCCCXX_L007.aligned.duplicates_marked.sorted.preBqsr.selfSM') as selfSM:
    reader = csv.DictReader(selfSM, delimiter='\t')
    i = 0
    for row in reader:
        if float(row["FREELK0"])==0 and float(row["FREELK1"])==0:
            # a zero value for the likelihoods implies no data. This usually indicates a problem rather than a real event.
            # if the bam isn't really empty, this is probably due to the use of a incompatible reference build between
            # vcf and bam.
           sys.stderr.write("Found zero likelihoods. Bam is either very-very shallow, or aligned to the wrong reference (relative to the vcf).")
           sys.exit(1)
        print(float(row["FREEMIX"])/0.75)
        i = i + 1
        # there should be exactly one row, and if this isn't the case the format of the output is unexpectedly different
        # and the results are not reliable.
        if i != 1:
            sys.stderr.write("Found %d rows in .selfSM file. Was expecting exactly 1. This is an error"%(i))
            sys.exit(2)
CODE     
	"""
# combining  gatk wdl workflow steps  "BaseRecalibrator" and GatherBQSRreports",??? "applyBQSR"??? will decide based on run time
# steps of generating base recalibrator and bqsr gather report steps with generating the recalibrated bam
# bc the apply bqsr step requries the gathered bqsr report
 # need a join intervals param in the params field that replaces the {{}} in the -L field
# need to include three separate known sites files
# possibly grab RG interval lists from the https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0/scattered_calling_intervals?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false
# and glob the interval numbers or use a numerical wildcard to glob the names.. or I may need to make this a separate module
#cat tsv_file_with_unmapped sequence_grouping.txt > interval_list.txt??
#-O ../output/recalibrated_bam/{wildcards.sample}.{wildcards.rg}.recal_data.csv  \

rule base_recalibrator_report:
   input: rules.sort_bam.output, 
   #output: "../output/recalibrated_bam/{sample}/{rg}.aligned.duplicates_marked.recalibrated.bam"
   output: "../output/recalibrated_bam/{sample}/{rg}.recal_data.csv"
#   params:
#       intervals= ' -L '.join(INTERVALS),
   log:
       "logs/recalibrated_bam/{sample}/{rg}.base_recal_report.gc_log.log"
   benchmark:
       "benchmarks/recalibrated_bam/{sample}/{rg}.bqsr_report.txt"
   shell:
       """
	module load R/3.5.3  gatk/4.2.0.0 java/1.8.0_211 python/3.7.3 picard/2.22.3

       ### BaseRecalibrator
       gatk --java-options "-XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal \
         -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails \
         -Xloggc:{log} -Xms5g" \
         BaseRecalibrator \
         -R {REF_FASTA} \
         -I {input} \
         --use-original-qualities \
         -O {output} \
         --known-sites {DBSNP_VCF} \
         --known-sites {KNOWN_SITES_MILLS1000G} \
         --known-sites {KNOWN_SITES_HOMOSAPIENS} 
	"""
# rule base_recalibrator_report:
#    input: rules.sort_bam.output, 
#    #output: "../output/recalibrated_bam/{sample}/{rg}.aligned.duplicates_marked.recalibrated.bam"
#    output: "../output/recalibrated_bam/{sample}/{rg}.recal_data.csv"
#    params:
#        intervals= ' -L '.join(INTERVALS),
#    log:
#        "logs/recalibrated_bam/{sample}/{rg}.log"
#    benchmark:
#        "benchmarks/recalibrated_bam/{sample}/{rg}.bqsr_report.txt"
#    shell:
#        """
# 	module load R/3.5.3  gatk/4.2.0.0 java/1.8.0_211 python/3.7.3 picard/2.22.3

#        ### BaseRecalibrator
#        gatk --java-options "-XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal \
#          -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails \
#          -Xloggc:gc_log.log -Xms5g" \
#          BaseRecalibrator \
#          -R {REF_FASTA} \
#          -I {input} \
#          --use-original-qualities \
#          -O {output} \
#          --known-sites {DBSNP_VCF} \
#          --known-sites {KNOWN_SITES_MILLS1000G} \
#          --known-sites {KNOWN_SITES_HOMOSAPIENS} \
#          -L {params.intervals}
# 	"""
rule apply_bqsr:
    input: bam=rules.sort_bam.output,recalibration_report=rules.base_recalibrator_report.output
    output: "../output/recalibrated_bam/{sample}/{rg}.aligned.duplicates_marked.recalibrated.bam"
    log:
       "logs/recalibrated_bam/{sample}/{rg}.apply_bqsr.gc_log.log"
    benchmark:
       "benchmarks/recalibrated_bam/{sample}/{rg}.apply_bqsr.txt"
    shell:
        """
        module load R/3.5.3  gatk/4.2.0.0 java/1.8.0_211 python/3.7.3 picard/2.22.3
        gatk --java-options "-XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps \
          -XX:+PrintGCDetails -Xloggc:{log} \
          -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Dsamjdk.compression_level={COMPRESSION_LEVEL} -Xms3000m" \
          ApplyBQSR \
          --create-output-bam-md5 \
          --add-output-sam-program-record \
          -R {REF_FASTA} \
          -I {input.bam} \
          --use-original-qualities \
          -O {output} \
          --bqsr-recal-file {input.recalibration_report} 
        """
    



                                                                                                                                                                                                                                                                                                                                         
