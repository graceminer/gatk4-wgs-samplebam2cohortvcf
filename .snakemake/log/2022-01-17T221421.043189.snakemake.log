The flag 'directory' used in rule mark_duplicates is only valid for outputs, not inputs.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 300
Job counts:
	count	jobs
	2	check_contamination
	2	crosscheck_fingerprints
	1	main
	2	sort_bam
	7

[Mon Jan 17 22:14:21 2022]
rule sort_bam:
    input: output/duplicates_marked/1102781231/1102781231.aligned.unsorted.duplicates_marked.bam
    output: output/sorted_bam/1102781231/1102781231.aligned.duplicates_marked.sorted.bam
    jobid: 3
    wildcards: sample=1102781231


[Mon Jan 17 22:14:21 2022]
rule sort_bam:
    input: output/duplicates_marked/1102777134/1102777134.aligned.unsorted.duplicates_marked.bam
    output: output/sorted_bam/1102777134/1102777134.aligned.duplicates_marked.sorted.bam
    jobid: 4
    wildcards: sample=1102777134

[Mon Jan 17 22:30:12 2022]
Error in rule sort_bam:
    jobid: 4
    output: output/sorted_bam/1102777134/1102777134.aligned.duplicates_marked.sorted.bam
    shell:
        
	module load R/3.5.3 java/1.8.0_211 python/3.7.3 picard/2.22.3

        java -Dsamjdk.compression_level=2 -Xms4000m -jar $PICARD           SortSam           INPUT=output/duplicates_marked/1102777134/1102777134.aligned.unsorted.duplicates_marked.bam           OUTPUT=output/sorted_bam/1102777134/1102777134.aligned.duplicates_marked.sorted.bam           SORT_ORDER="coordinate"           CREATE_INDEX=true           CREATE_MD5_FILE=true           MAX_RECORDS_IN_RAM=300000
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Error executing rule sort_bam on cluster (jobid: 4, external: 291618, jobscript: /sc/arion/projects/MMAAAS/ngs_res/aaa_pilot_20201113/gatk20220113/.snakemake/tmp._ue86gb9/snakejob.sort_bam.4.sh). For error details see the cluster log and the log files of the involved rule(s).
[Mon Jan 17 22:31:22 2022]
Error in rule sort_bam:
    jobid: 3
    output: output/sorted_bam/1102781231/1102781231.aligned.duplicates_marked.sorted.bam
    shell:
        
	module load R/3.5.3 java/1.8.0_211 python/3.7.3 picard/2.22.3

        java -Dsamjdk.compression_level=2 -Xms4000m -jar $PICARD           SortSam           INPUT=output/duplicates_marked/1102781231/1102781231.aligned.unsorted.duplicates_marked.bam           OUTPUT=output/sorted_bam/1102781231/1102781231.aligned.duplicates_marked.sorted.bam           SORT_ORDER="coordinate"           CREATE_INDEX=true           CREATE_MD5_FILE=true           MAX_RECORDS_IN_RAM=300000
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Error executing rule sort_bam on cluster (jobid: 3, external: 291616, jobscript: /sc/arion/projects/MMAAAS/ngs_res/aaa_pilot_20201113/gatk20220113/.snakemake/tmp._ue86gb9/snakejob.sort_bam.3.sh). For error details see the cluster log and the log files of the involved rule(s).
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /sc/arion/projects/MMAAAS/ngs_res/aaa_pilot_20201113/gatk20220113/.snakemake/log/2022-01-17T221421.043189.snakemake.log
