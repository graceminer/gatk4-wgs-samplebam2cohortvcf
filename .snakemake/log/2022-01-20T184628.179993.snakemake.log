Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	100	gatk4_haplotype_caller
	1	main
	101

[Thu Jan 20 18:46:28 2022]
rule gatk4_haplotype_caller:
    input: output/final_bam/1102781231.final.bam
    output: output/gvcf/1102781231.13.g.vcf.gz
    jobid: 13
    benchmark: benchmarks/gvcf/1102781231.gvcf.13.txt
    wildcards: sample=1102781231, intervals=13

Terminating processes on user request, this might take some time.
[Thu Jan 20 18:46:55 2022]
Error in rule gatk4_haplotype_caller:
    jobid: 13
    output: output/gvcf/1102781231.13.g.vcf.gz
    shell:
        
        module load R/3.5.3  gatk/4.2.0.0 java/1.8.0_211 python/3.7.3 picard/2.22.3
        
        interval_file=$(ls input/scatter_interval_list/*/13scattered.interval_list)
        set -e
        gatk --java-options "-Xms6000m -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10"           HaplotypeCaller           -R /sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/resources-broad-hg38-v0-Homo_sapiens_assembly38.fasta           -I output/final_bam/1102781231.final.bam           -L $interval_file           -O output/gvcf/1102781231.13.g.vcf.gz           -contamination 0.0           -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation           -new-qual           -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90           -ERC GVCF 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job gatk4_haplotype_caller since they might be corrupted:
output/gvcf/1102781231.13.g.vcf.gz
Complete log: /sc/arion/projects/MMAAAS/ngs_res/aaa_pilot_20201113/gatk20220113/.snakemake/log/2022-01-20T184628.179993.snakemake.log
