Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	main
	1	scatter_interval_list
	2

[Thu Jan 20 00:06:14 2022]
rule scatter_interval_list:
    input: /sc/arion/projects/MMAAAS/src/gatk-resources/hg38_20201116/hg38/v0/resources-broad-hg38-v0-wgs_calling_regions.hg38.interval_list
    output: input/scatter_interval_list/
    jobid: 4
    benchmark: benchmarks/scatter_interval_list/scatter_interval_list.txt

[Thu Jan 20 00:06:18 2022]
Finished job 4.
1 of 2 steps (50%) done

[Thu Jan 20 00:06:18 2022]
localrule main:
    input: input/1102781231.final.bam, input/1102777134.final.bam, output/split_rg/1102781231/, output/split_rg/1102777134/, input/intervals/sequence_grouping.tsv, input/intervals/sequence_grouping.unmapped.tsv, input/scatter_interval_list/
    jobid: 0

[Thu Jan 20 00:06:18 2022]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /sc/arion/projects/MMAAAS/ngs_res/aaa_pilot_20201113/gatk20220113/.snakemake/log/2022-01-20T000614.016072.snakemake.log
